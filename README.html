<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Algorithm Reference</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f8f9fa;
        }
        
        .container {
            max-width: 1000px;
            margin: 0 auto;
            padding: 2rem;
            background: white;
            min-height: 100vh;
            box-shadow: 0 0 20px rgba(0,0,0,0.1);
        }
        
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem;
            margin: -2rem -2rem 2rem -2rem;
            border-radius: 0 0 15px 15px;
        }
        
        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
        }
        
        .header p {
            opacity: 0.9;
            font-size: 1.1rem;
        }
        
        .back-link {
            display: inline-block;
            background: #667eea;
            color: white;
            padding: 0.5rem 1rem;
            text-decoration: none;
            border-radius: 5px;
            margin-bottom: 2rem;
            transition: background 0.2s;
        }
        
        .back-link:hover {
            background: #5a67d8;
        }
        
        h1, h2, h3 {
            color: #2d3748;
            margin: 2rem 0 1rem 0;
        }
        
        h1 {
            font-size: 2.2rem;
            border-bottom: 3px solid #667eea;
            padding-bottom: 0.5rem;
        }
        
        h2 {
            font-size: 1.8rem;
            border-bottom: 2px solid #e2e8f0;
            padding-bottom: 0.3rem;
        }
        
        h3 {
            font-size: 1.4rem;
            color: #4a5568;
        }
        
        p {
            margin-bottom: 1rem;
            color: #4a5568;
        }
        
        code {
            background: #f1f5f9;
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            font-size: 0.9rem;
            color: #e53e3e;
        }
        
        pre {
            background: #2d3748;
            color: #e2e8f0;
            padding: 1rem;
            border-radius: 8px;
            overflow-x: auto;
            margin: 1rem 0;
        }
        
        pre code {
            background: none;
            color: inherit;
            padding: 0;
        }
        
        ul, ol {
            margin: 1rem 0 1rem 2rem;
        }
        
        li {
            margin-bottom: 0.5rem;
            color: #4a5568;
        }
        
        a {
            color: #667eea;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
        }
        
        th, td {
            border: 1px solid #e2e8f0;
            padding: 0.75rem;
            text-align: left;
        }
        
        th {
            background: #f8f9fa;
            font-weight: 600;
            color: #2d3748;
        }
        
        .footer {
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 1px solid #e2e8f0;
            text-align: center;
            color: #4a5568;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Algorithm Reference</h1>
            <p>Algorithm Study Repository Documentation</p>
        </div>
        
        <a href="index.html" class="back-link">← Back to Home</a>
        
        <div class="content">
            <h1>Algorithms — Implementations & Thorough Documentation</h1></p><p><strong>Scope & deliverable</strong>: This document contains for each requested algorithm (1) a concise technical overview, (2) origin / who created it and when, (3) the core idea and intuition, (4) a short formal / mathematical representation (recurrence relations, correctness invariants), (5) complexity bounds, (6) a TypeScript implementation compatible with <strong>Deno / Bun</strong>, and (7) pragmatic notes and usage guidance including common pitfalls.</p><p>> <em>Style</em>: rigorous, practical, production-minded. Use this as both a learning resource and a deliverable you can copy into a codebase or documentation portal.</p><p>---</p><p><h2>Table of contents</h2></p><p><ul><li>Binary Search</li><br><li>Knuth–Morris–Pratt (KMP)</li><br><li>Quick Sort</li><br><li>Merge Sort</li><br><li>Fast Fourier Transform (FFT)</li><br><li>Depth-First Search (DFS)</li><br><li>Breadth-First Search (BFS)</li><br><li>Topological Sort</li><br><li>Lowest Common Ancestor (LCA)</li><br><li>A\* Search</li><br><li>Dijkstra Shortest Path</li><br><li>Minimum Spanning Tree (Kruskal)</li><br><li>Binary Exponentiation</li><br><li>Knapsack (0/1) — Dynamic Programming</li><br><li>Longest Common Subsequence (LCS)</li><br><li>Greatest Common Divisor (GCD)</li></p><p>---</p><p>> <strong>Notes on the code</strong>: All TypeScript examples are written so they run on recent <strong>Deno</strong> or <strong>Bun</strong> builds. They avoid browser-only or Node-only APIs. Each implementation is intentionally idiomatic and clear rather than hyper-optimized; replace micro-structures (like heap) with highly-tuned libraries in production if you need raw throughput.</p><p>---</p><p><h1>1) Binary Search</h1></p><p><strong>Overview</strong><br>Binary search locates the position of a target value within a sorted array by repeatedly halving the search interval. It is the canonical example of logarithmic-time search.</p><p><strong>Origin</strong><br>Binary search is an old technique in algorithmic thinking; its first references in computing literature appear in early papers and textbooks. It was discussed in early computer literature (e.g., John Mauchly & early ACM-era texts) and formalized in modern algorithm textbooks (Knuth and others).</p><p><strong>Core idea</strong><br>Compare the target to the middle element; if equal, return; otherwise discard half of the array (where the target cannot be) and repeat.</p><p><strong>Mathematical representation / proof sketch</strong><br>If <code>n</code> elements remain, one comparison reduces the domain to at most <code>⌈n/2⌉</code>. The recurrence for cost <code>T(n)</code> (number of comparisons) is:</p><p><pre><code><br>T(n) = T(n/2) + O(1)<br></code></pre></p><p>Solving gives <code>T(n) = O(log n)</code>.</p><p><strong>Complexity</strong><br>Time: <code>O(log n)</code> worst/average, <code>O(1)</code> best (if found at mid)<br>Space: <code>O(1)</code> (iterative)</p><p><strong>Implementation (TypeScript — iterative)</strong></p><p><pre><code>ts<br>export function binarySearch(arr: number[], target: number): number {<br>  let lo = 0, hi = arr.length - 1;<br>  while (lo <= hi) {<br>    const mid = (lo + hi) >> 1;<br>    const v = arr[mid];<br>    if (v === target) return mid;<br>    if (v < target) lo = mid + 1;<br>    else hi = mid - 1;<br>  }<br>  return -1;<br>}<br></code></pre></p><p><strong>Practical notes</strong></p><p><li>Off-by-one errors are common; always choose consistent invariants (e.g., <code>[lo, hi]</code> inclusive vs <code>[lo, hi)</code> exclusive).</li><br><li>For floating point or comparator-based search, the comparator must induce a strict weak ordering.</li></p><p>---</p><p><h1>2) Knuth–Morris–Pratt (KMP) — string search</h1></p><p><strong>Overview</strong><br>KMP finds all occurrences of a pattern <code>P</code> of length <code>m</code> in text <code>T</code> of length <code>n</code> in <code>O(n + m)</code> time by precomputing a failure table (prefix function) that tells how much the pattern can be shifted after a mismatch.</p><p><strong>Origin</strong><br>Published by Donald Knuth, James H. Morris, Jr., and Vaughan Pratt in 1977; known as the Knuth–Morris–Pratt algorithm.</p><p><strong>Core idea</strong><br>Precompute the longest proper prefix of the pattern that is also a suffix ending at each position. On mismatch, jump the pattern forward using that table rather than restarting from the beginning.</p><p><strong>Mathematical representation</strong><br>Define the prefix function <code>π[i]</code> as the length of the longest proper prefix of <code>P[0..i]</code> that is also a suffix. The computation of <code>π</code> runs in <code>O(m)</code>. The scan of text uses <code>π</code> to keep <code>j</code>, the current matched length, non-decreasing overall (across scans), yielding total <code>O(n)</code>.</p><p><strong>Complexity</strong><br>Time: <code>O(n + m)</code><br>Space: <code>O(m)</code> for the prefix table</p><p><strong>Implementation</strong></p><p><pre><code>ts<br>export function kmpSearch(text: string, pattern: string): number[] {<br>  const n = text.length, m = pattern.length;<br>  if (m === 0) return [];<br>  const pi = new Array(m).fill(0);<br>  for (let i = 1; i < m; i++) {<br>    let j = pi[i - 1];<br>    while (j > 0 && pattern[i] !== pattern[j]) j = pi[j - 1];<br>    if (pattern[i] === pattern[j]) j++;<br>    pi[i] = j;<br>  }<br>  const results: number[] = [];<br>  let j = 0;<br>  for (let i = 0; i < n; i++) {<br>    while (j > 0 && text[i] !== pattern[j]) j = pi[j - 1];<br>    if (text[i] === pattern[j]) j++;<br>    if (j === m) { results.push(i - m + 1); j = pi[j - 1]; }<br>  }<br>  return results;<br>}<br></code></pre></p><p><strong>Practical notes</strong></p><p><li>Works best when pattern is not tiny; for many very-short patterns, Boyer–Moore variants or simple memchr-like operations can be faster in practice.</li></p><p>---</p><p><h1>3) Quick Sort</h1></p><p><strong>Overview</strong><br>QuickSort is a divide-and-conquer sort that partitions around a pivot, then recursively sorts partitions.</p><p><strong>Origin</strong><br>Developed by C. A. R. (Tony) Hoare in 1959 and published in 1961.</p><p><strong>Core idea</strong><br>Select a pivot, partition the array so items < pivot are left and > pivot are right, recurse. Average cost <code>O(n log n)</code>; worst-case <code>O(n^2)</code> when partitions are highly unbalanced (e.g., sorted input with poor pivot choice).</p><p><strong>Mathematical representation</strong><br>Recurrence (average balanced split):</p><p><pre><code><br>T(n) = 2 T(n/2) + O(n) => T(n) = O(n log n)<br></code></pre></p><p>Worst-case (bad pivot):</p><p><pre><code><br>T(n) = T(n-1) + O(n) => O(n^2)<br></code></pre></p><p><strong>Complexity</strong><br>Time: average <code>O(n log n)</code>, worst <code>O(n^2)</code>.<br>Space: <code>O(log n)</code> auxiliary with good in-place partitioning.</p><p><strong>Implementation (randomized pivot; in-place)</strong></p><p><pre><code>ts<br>export function quickSort(arr: number[]): number[] {<br>  const a = arr.slice();<br>  function qs(l: number, r: number) {<br>    if (l >= r) return;<br>    const pivotIdx = l + Math.floor(Math.random() * (r - l + 1));<br>    const pivot = a[pivotIdx];<br>    let i = l, j = r;<br>    while (i <= j) {<br>      while (a[i] < pivot) i++;<br>      while (a[j] > pivot) j--;<br>      if (i <= j) { [a[i], a[j]] = [a[j], a[i]]; i++; j--; }<br>    }<br>    if (l < j) qs(l, j);<br>    if (i < r) qs(i, r);<br>  }<br>  qs(0, a.length - 1);<br>  return a;<br>}<br></code></pre></p><p><strong>Practical notes</strong></p><p><li>Use randomized pivot or median-of-three to avoid worst-case on sorted inputs.</li><br><li>If worst-case guarantees are required, use introsort (hybrid QuickSort + HeapSort).</li></p><p>---</p><p><h1>4) Merge Sort</h1></p><p><strong>Overview</strong><br>Merge Sort recursively splits the array, sorts halves, and merges them back. Stable by design.</p><p><strong>Origin</strong><br>Invented by John von Neumann in 1945.</p><p><strong>Core idea</strong><br>Divide the array into two halves, sort both halves recursively, then merge the sorted halves with a linear pass.</p><p><strong>Mathematical representation</strong><br>Recurrence: <code>T(n) = 2 T(n/2) + Θ(n)</code> ⇒ <code>T(n) = Θ(n log n)</code> (Master Theorem)</p><p><strong>Complexity</strong><br>Time: <code>O(n log n)</code> worst/average/best; Space: <code>O(n)</code> auxiliary (top-down). Can implement in-place variants but more complex.</p><p><strong>Implementation</strong></p><p><pre><code>ts<br>export function mergeSort(arr: number[]): number[] {<br>  if (arr.length <= 1) return arr.slice();<br>  const mid = (arr.length / 2) | 0;<br>  const left = mergeSort(arr.slice(0, mid));<br>  const right = mergeSort(arr.slice(mid));<br>  const out: number[] = [];<br>  let i = 0, j = 0;<br>  while (i < left.length && j < right.length) {<br>    if (left[i] <= right[j]) out.push(left[i++]); else out.push(right[j++]);<br>  }<br>  while (i < left.length) out.push(left[i++]);<br>  while (j < right.length) out.push(right[j++]);<br>  return out;<br>}<br></code></pre></p><p><strong>Practical notes</strong></p><p><li>Stable sorting; use when preserving input order on ties matters.</li><br><li>Useful for external sorting (merge phase fits I/O patterns).</li></p><p>---</p><p><h1>5) Fast Fourier Transform (FFT)</h1></p><p><strong>Overview</strong><br>FFT computes the Discrete Fourier Transform (DFT) of a sequence in <code>O(n log n)</code> time. The DFT transforms a sequence from time domain to frequency domain. FFT reduces naive <code>O(n^2)</code> DFT cost.</p><p><strong>Origin</strong><br>The Cooley–Tukey algorithm (the modern FFT) was published in 1965 by J. W. Cooley and John Tukey; earlier mathematicians (notably Gauss) had similar divide-and-conquer observations for special sizes.</p><p><strong>Core idea</strong><br>Factor the DFT of size <code>N = N1*N2</code> into smaller DFTs. The radix-2 Cooley–Tukey variant repeatedly splits even/odd indices and recombines using twiddle factors <code>ω = e^{-2π i / N}</code>. Complexity <code>O(N log N)</code>.</p><p><strong>Mathematical representation</strong><br>Discrete Fourier Transform (DFT):</p><p>$X_k = \sum_{n=0}^{N-1} x_n e^{-2\pi i k n / N}$</p><p>Cooley–Tukey radix-2 recurrence (N even):</p><p>$X_k = E_k + \omega_N^k \cdot O_k$<br>$X_{k+N/2} = E_k - \omega_N^k \cdot O_k$</p><p>where <code>E</code> and <code>O</code> are DFTs of even and odd indexed subsequences.</p><p><strong>Complexity</strong><br>Time: <code>O(N log N)</code> for highly composite N<br>Space: <code>O(N)</code> (typical implementations)</p><p><strong>Implementation (simple recursive complex class)</strong></p><p><pre><code>ts<br>class Complex { constructor(public re = 0, public im = 0) {} add(b: Complex) { return new Complex(this.re + b.re, this.im + b.im); } sub(b: Complex) { return new Complex(this.re - b.re, this.im - b.im); } mul(b: Complex) { return new Complex(this.re<em>b.re - this.im</em>b.im, this.re<em>b.im + this.im</em>b.re); } }<br>function isPowerOfTwo(n: number) { return (n & (n - 1)) === 0; }<br>export function fft(input: Complex[], invert = false): Complex[] {<br>  const n = input.length;<br>  if (!isPowerOfTwo(n)) throw new Error("FFT input length must be power of 2");<br>  if (n === 1) return [new Complex(input[0].re, input[0].im)];<br>  const even = fft(input.filter((_, i) => (i & 1) === 0), invert);<br>  const odd = fft(input.filter((_, i) => (i & 1) === 1), invert);<br>  const ang = (2 <em> Math.PI) / n </em> (invert ? -1 : 1);<br>  const out = new Array(n);<br>  for (let k = 0; k < n / 2; k++) {<br>    const w = new Complex(Math.cos(ang<em>k), Math.sin(ang</em>k));<br>    const t = w.mul(odd[k]);<br>    out[k] = even[k].add(t);<br>    out[k + n/2] = even[k].sub(t);<br>  }<br>  if (invert) for (let i = 0; i < n; i++) { out[i].re /= 2; out[i].im /= 2; }<br>  return out;<br>}<br></code></pre></p><p><strong>Practical notes</strong></p><p><li>Recursive FFT is easy to read; iterative in-place FFT with bit-reversal is faster and memory-friendlier for large <code>N</code>.</li><br><li>For production DSP, use a library or a WebAssembly implementation.</li></p><p>---</p><p><h1>6) Depth-First Search (DFS)</h1></p><p><strong>Overview</strong><br>DFS explores as far as possible along each branch before backtracking. It is used for connected components, cycle detection, topological sorting (via finishing times), and many graph algorithms.</p><p><strong>Origin</strong><br>A DFS-like approach was used in maze-solving by Charles Pierre Trémaux in the 19th century; modern formalizations emerged in early CS literature.</p><p><strong>Core idea</strong><br>Recursively visit unvisited neighbors, marking nodes as visited; stack-based traversal equivalent.</p><p><strong>Mathematical representation</strong><br>DFS runs in <code>O(V + E)</code> where V = number of vertices and E = number of edges; each vertex and edge is processed at most a constant number of times in adjacency-list representation.</p><p><strong>Implementation (recursive)</strong></p><p><pre><code>ts<br>export function dfs(adj: number[][], start: number): number[] {<br>  const n = adj.length; const visited = new Array(n).fill(false); const out: number[] = [];<br>  function go(u: number) { visited[u] = true; out.push(u); for (const v of adj[u]) if (!visited[v]) go(v); }<br>  go(start);<br>  return out;<br>}<br></code></pre></p><p><strong>Practical notes</strong></p><p><li>For very deep graphs use iterative DFS to avoid call-stack overflow, or increase stack allowance if runtime supports it.</li></p><p>---</p><p><h1>7) Breadth-First Search (BFS)</h1></p><p><strong>Overview</strong><br>BFS explores vertices in layers by increasing distance from the start node. It gives shortest paths (in unweighted graphs) and runs in <code>O(V + E)</code>.</p><p><strong>Origin</strong><br>BFS concepts appear in early computing history (Konrad Zuse’s work 1940s) and rediscovered and popularized by Edward F. Moore in 1959.</p><p><strong>Core idea</strong><br>Use a queue; visit neighbors and enqueue them. Each step processes a node and its adjacency list.</p><p><strong>Implementation</strong></p><p><pre><code>ts<br>export function bfs(adj: number[][], start: number): number[] {<br>  const n = adj.length; const visited = new Array(n).fill(false); const q: number[] = []; const out: number[] = [];<br>  visited[start] = true; q.push(start);<br>  while (q.length) {<br>    const u = q.shift()!; out.push(u);<br>    for (const v of adj[u]) if (!visited[v]) { visited[v] = true; q.push(v); }<br>  }<br>  return out;<br>}<br></code></pre></p><p><strong>Practical notes</strong></p><p><li>For large graphs, using <code>shift()</code> may be O(n) in some JS runtimes; prefer a circular buffer queue for high-throughput needs.</li></p><p>---</p><p><h1>8) Topological Sort</h1></p><p><strong>Overview</strong><br>A topological order of a DAG is a linear ordering of vertices such that for every directed edge <code>u -> v</code>, <code>u</code> comes before <code>v</code>.</p><p><strong>Origin</strong><br>A standard algorithm using Kahn's method was described by Arthur B. Kahn (1962). DFS-based topological sorting (ordering by finishing times) is another classic approach.</p><p><strong>Core idea</strong><br>Kahn’s algorithm: repeatedly remove nodes with in-degree 0 and append to ordering; reduce indegrees of neighbors.</p><p><strong>Algorithmic invariants / correctness</strong><br>If the graph has a cycle, Kahn's algorithm cannot remove all nodes; the remaining nodes indicate a cycle.</p><p><strong>Implementation (Kahn)</strong></p><p><pre><code>ts<br>export function topologicalSort(adj: number[][]): number[] | null {<br>  const n = adj.length; const indeg = new Array(n).fill(0);<br>  for (let u = 0; u < n; u++) for (const v of adj[u]) indeg[v]++;<br>  const q: number[] = [];<br>  for (let i = 0; i < n; i++) if (indeg[i] === 0) q.push(i);<br>  const order: number[] = [];<br>  while (q.length) {<br>    const u = q.shift()!; order.push(u);<br>    for (const v of adj[u]) { indeg[v]--; if (indeg[v] === 0) q.push(v); }<br>  }<br>  if (order.length !== n) return null; // cycle<br>  return order;<br>}<br></code></pre></p><p><strong>Complexity</strong><br>Time: <code>O(V + E)</code></p><p>---</p><p><h1>9) Lowest Common Ancestor (LCA)</h1></p><p><strong>Overview</strong><br>Given a rooted tree, the LCA of nodes <code>u</code> and <code>v</code> is the deepest node that is ancestor to both. Efficient methods preprocess the tree to answer queries fast.</p><p><strong>Origin</strong><br>The problem statement was formalized by Aho, Hopcroft, and Ullman (1973). Optimal linear-time preprocessing with constant-time queries was achieved by Harel & Tarjan (1984) and later simplified by others; Tarjan (off-line LCA) produced an efficient offline algorithm in 1979.</p><p><strong>Core idea</strong><br>Binary lifting (sparse table) preprocesses parents <code>2^k</code> above each node so queries shift nodes to the same depth and then jump both upward by powers of two.</p><p><strong>Mathematical representation</strong><br>Precompute <code>up[k][v] = ancestor of v 2^k steps above</code> for <code>k</code> in <code>[0, log N)</code>. Then to raise a node by distance <code>d</code>, decompose <code>d</code> in binary and climb by <code>up[k]</code> accordingly.</p><p><strong>Complexity</strong><br>Preprocess: <code>O(N log N)</code> time and <code>O(N log N)</code> space. Query: <code>O(log N)</code>.</p><p><strong>Implementation (binary lifting)</strong></p><p><pre><code>ts<br>export class LCA {<br>  n: number; LOG: number; up: number[][]; depth: number[]; adj: number[][];<br>  constructor(adj: number[][], root = 0) {<br>    this.n = adj.length; this.adj = adj; this.LOG = Math.ceil(Math.log2(Math.max(2, this.n)));<br>    this.up = Array.from({ length: this.LOG }, () => new Array(this.n).fill(-1));<br>    this.depth = new Array(this.n).fill(0);<br>    this.dfs(root, root);<br>    for (let k = 1; k < this.LOG; k++) for (let v = 0; v < this.n; v++) {<br>      const mid = this.up[k - 1][v]; this.up[k][v] = mid === -1 ? -1 : this.up[k - 1][mid];<br>    }<br>  }<br>  private dfs(u: number, p: number) {<br>    this.up[0][u] = p;<br>    for (const v of this.adj[u]) if (v !== p) { this.depth[v] = this.depth[u] + 1; this.dfs(v, u); }<br>  }<br>  query(u: number, v: number): number {<br>    if (this.depth[u] < this.depth[v]) [u, v] = [v, u];<br>    let diff = this.depth[u] - this.depth[v];<br>    for (let k = 0; k < this.LOG; k++) if (diff & (1 << k)) u = this.up[k][u];<br>    if (u === v) return u;<br>    for (let k = this.LOG - 1; k >= 0; k--) {<br>      if (this.up[k][u] !== this.up[k][v]) { u = this.up[k][u]; v = this.up[k][v]; }<br>    }<br>    return this.up[0][u];<br>  }<br>}<br></code></pre></p><p><strong>Practical notes</strong></p><p><li>Binary lifting is straightforward and efficient for many use cases. Use Euler tour + RMQ or Farach–Colton & Bender for constant-time queries if you have high query volume and need faster answers.</li></p><p>---</p><p><h1>10) A\* Search</h1></p><p><strong>Overview</strong><br>A\* is a best-first search algorithm that uses <code>f(n) = g(n) + h(n)</code> to guide exploration, where <code>g(n)</code> is cost from start to node <code>n</code>, and <code>h(n)</code> is a heuristic estimate of cost from <code>n</code> to goal.</p><p><strong>Origin</strong><br>Published by Peter Hart, Nils Nilsson and Bertram Raphael (SRI) in 1968.</p><p><strong>Core idea</strong><br>If <code>h</code> is admissible (never overestimates true remaining cost), A\* returns an optimal path; the heuristic narrows exploration to promising nodes.</p><p><strong>Mathematical representation</strong><br><code>f(n) = g(n) + h(n)</code>. For admissibility: <code>∀n, h(n) ≤ h<em>(n)</code> where <code>h</em>(n)</code> is true cost to goal.</p><p><strong>Implementation (grid, Manhattan heuristic)</strong></p><p><pre><code>ts<br>type NodeKey = string; function key(x: number, y: number) { return <code>${x},${y}</code>; }<br>export function astarGrid(start: [number, number], goal: [number, number], grid: number[][]) {<br>  const R = grid.length, C = grid[0].length;<br>  const inBounds = (x: number, y: number) => x >= 0 && y >= 0 && x < R && y < C;<br>  const h = (x: number, y: number) => Math.abs(x - goal[0]) + Math.abs(y - goal[1]);<br>  const open = new Map<NodeKey, number>(); const gScore = new Map<NodeKey, number>(); const parent = new Map<NodeKey, NodeKey | null>();<br>  const startKey = key(start[0], start[1]); open.set(startKey, h(start[0], start[1])); gScore.set(startKey, 0); parent.set(startKey, null);<br>  const dirs = [[1,0],[-1,0],[0,1],[0,-1]];<br>  while (open.size) {<br>    let curKey: NodeKey | null = null; let curF = Infinity;<br>    for (const [k, f] of open) if (f < curF) { curF = f; curKey = k; }<br>    if (!curKey) break;<br>    open.delete(curKey);<br>    const [cx, cy] = curKey.split(',').map(Number);<br>    if (cx === goal[0] && cy === goal[1]) { const path: [number, number][] = []; let p: NodeKey | null = curKey; while (p) { path.push(p.split(',').map(Number) as [number, number]); p = parent.get(p) ?? null; } path.reverse(); return path; }<br>    const gCur = gScore.get(curKey)!;<br>    for (const [dx, dy] of dirs) {<br>      const nx = cx + dx, ny = cy + dy;<br>      if (!inBounds(nx, ny) || grid[nx][ny] === 1) continue;<br>      const nk = key(nx, ny); const tentativeG = gCur + 1;<br>      if (tentativeG < (gScore.get(nk) ?? Infinity)) { parent.set(nk, curKey); gScore.set(nk, tentativeG); open.set(nk, tentativeG + h(nx, ny)); }<br>    }<br>  }<br>  return null;<br>}<br></code></pre></p><p><strong>Practical notes</strong></p><p><li>The choice of heuristic is mission-critical: admissible + consistent heuristics give optimality and faster convergence.</li><br><li>Implement open set as a binary heap (priority queue) for performance; using a Map and scanning min is simple but slow.</li></p><p>---</p><p><h1>11) Dijkstra Shortest Path</h1></p><p><strong>Overview</strong><br>Dijkstra finds shortest paths from a source to all nodes in a weighted graph with non-negative edge weights.</p><p><strong>Origin</strong><br>Conceived by Edsger W. Dijkstra in 1956; published in 1959.</p><p><strong>Core idea</strong><br>Greedy relaxation using a priority queue: pick the unsettled node with smallest tentative distance, relax its edges.</p><p><strong>Mathematical representation</strong><br>Correctness follows from the non-negativity of edge weights which guarantees that when a node is extracted from the priority queue, its shortest distance is finalized.</p><p><strong>Complexity</strong><br>With a binary heap: <code>O((V + E) log V)</code>. With Fibonacci heap: <code>O(V log V + E)</code>.</p><p><strong>Implementation (binary heap)</strong></p><p><pre><code>ts<br>class MinHeap<T> { data: { key: number; val: T }[] = [];<br>  size() { return this.data.length; }<br>  push(key: number, val: T) { this.data.push({ key, val }); let i = this.data.length - 1; while (i > 0) { const p = ((i - 1) >> 1); if (this.data[p].key <= this.data[i].key) break; [this.data[p], this.data[i]] = [this.data[i], this.data[p]]; i = p; } }<br>  pop(): { key:number; val:T } | null { if (!this.data.length) return null; const res = this.data[0]; const last = this.data.pop()!; if (this.data.length) { this.data[0] = last; let i = 0; while (true) { const l = i<em>2+1, r = i</em>2+2; let s = i; if (l < this.data.length && this.data[l].key < this.data[s].key) s = l; if (r < this.data.length && this.data[r].key < this.data[s].key) s = r; if (s === i) break; [this.data[i], this.data[s]] = [this.data[s], this.data[i]]; i = s; } } return res; } }</p><p>export function dijkstra(adj: Array<Array<[number, number]>>, src: number): number[] {<br>  const n = adj.length; const dist = new Array(n).fill(Infinity); dist[src] = 0; const pq = new MinHeap<number>(); pq.push(0, src);<br>  while (pq.size()) {<br>    const cur = pq.pop()!; const u = cur.val; const d = cur.key; if (d > dist[u]) continue;<br>    for (const [v, w] of adj[u]) if (dist[v] > dist[u] + w) { dist[v] = dist[u] + w; pq.push(dist[v], v); }<br>  }<br>  return dist;<br>}<br></code></pre></p><p><strong>Practical notes</strong></p><p><li>Dijkstra requires non-negative weights. For negative weights, use Bellman–Ford or Johnson's algorithm for all-pairs.</li><br><li>Use an indexed priority queue when you need <code>decrease-key</code> support for performance.</li></p><p>---</p><p><h1>12) Minimum Spanning Tree — Kruskal</h1></p><p><strong>Overview</strong><br>Kruskal builds an MST by sorting edges by weight and adding them unless they create a cycle (checked by union-find).</p><p><strong>Origin</strong><br>Published by Joseph Kruskal in 1956.</p><p><strong>Core idea</strong><br>Greedily take smallest edges that connect components; use disjoint-set (union-find) to detect cycles.</p><p><strong>Complexity</strong><br>Sorting edges <code>O(E log E)</code> dominates; union-find operations are nearly <code>O(1)</code> amortized (inverse-Ackermann).</p><p><strong>Implementation</strong></p><p><pre><code>ts<br>export function kruskal(n: number, edges: Array<[number, number, number]>) {<br>  edges = edges.slice().sort((a,b) => a[2] - b[2]);<br>  const parent = new Array(n).fill(0).map((_,i)=>i); const rank = new Array(n).fill(0);<br>  function find(a:number):number { if (parent[a] !== a) parent[a] = find(parent[a]); return parent[a]; }<br>  function unite(a:number,b:number){ a = find(a); b = find(b); if (a===b) return false; if (rank[a]<rank[b]) [a,b]=[b,a]; parent[b]=a; if (rank[a]===rank[b]) rank[a]++; return true; }<br>  const mst: Array<[number, number, number]> = [];<br>  for (const e of edges) if (unite(e[0], e[1])) mst.push(e);<br>  return mst;<br>}<br></code></pre></p><p><strong>Practical notes</strong></p><p><li>Kruskal is excellent for sparse graphs; Prim’s algorithm is often preferred for dense graphs (especially with fast adjacency / Fibonacci heap).</li></p><p>---</p><p><h1>13) Binary Exponentiation (Exponentiation by Squaring)</h1></p><p><strong>Overview</strong><br>Efficiently compute <code>a^n</code> in <code>O(log n)</code> multiplications by exponentiation by squaring.</p><p><strong>Origin</strong><br>A classical mathematical technique; in computing it’s called binary exponentiation (square-and-multiply). The idea is ancient in arithmetic; modern algorithmic formulation is standard.</p><p><strong>Mathematical representation</strong><br>Using binary expansion of <code>n</code>: if <code>n = sum b_k 2^k</code>, then <code>a^n = product over k with b_k=1 of a^{2^k}</code>. Recurrence:</p><p><pre><code><br>pow(a, n): if n==0 return 1; t = pow(a, floor(n/2)); if n%2==0 return t<em>t else return t</em>t*a<br></code></pre></p><p><strong>Implementation</strong></p><p><pre><code>ts<br>export function binPow(base: number | bigint, exp: number): number | bigint {<br>  let b = typeof base === 'bigint' ? base : BigInt(Math.floor(base));<br>  let e = BigInt(exp);<br>  let res = BigInt(1);<br>  while (e > 0) {<br>    if (e & BigInt(1)) res *= b;<br>    b *= b;<br>    e >>= BigInt(1);<br>  }<br>  if (typeof base === 'number') {<br>    const num = Number(res);<br>    if (Number.isFinite(num) && Math.abs(num) <= Number.MAX_SAFE_INTEGER) return num;<br>  }<br>  return res;<br>}<br></code></pre></p><p><strong>Practical notes</strong></p><p><li>Use modular reductions inside loops for modular exponentiation (modular exponentiation is central to cryptography). Use BigInt in JS/TS if exponents/results overflow 53-bit safe integers.</li></p><p>---</p><p><h1>14) Knapsack Problem (0/1) — dynamic programming</h1></p><p><strong>Overview</strong><br>Given <code>n</code> items with weights <code>w_i</code> and values <code>v_i</code>, choose subset with total weight ≤ <code>W</code> that maximizes total value.</p><p><strong>Origin</strong><br>A classical optimization / combinatorial problem; formalized in operations research and CS literature in the mid-20th century and widely studied as an NP-hard family (decision variant can be NP-complete). The dynamic programming pseudo-polynomial algorithm is classical.</p><p><strong>Mathematical representation</strong><br>DP recurrence for 0/1 knapsack:</p><p><pre><code><br>DP[i][w] = max(DP[i-1][w], DP[i-1][w-w_i] + v_i)  (if w >= w_i)<br></code></pre></p><p>Space-optimized: use one-dimensional <code>dp[w]</code> iterating items outer loop and weight inner loop in decreasing order.</p><p><strong>Implementation (1D DP)</strong></p><p><pre><code>ts<br>export function knapsack(values: number[], weights: number[], W: number) {<br>  const n = values.length; const dp = new Array(W + 1).fill(0);<br>  for (let i = 0; i < n; i++) {<br>    for (let w = W; w >= weights[i]; w--) {<br>      dp[w] = Math.max(dp[w], dp[w - weights[i]] + values[i]);<br>    }<br>  }<br>  return dp[W];<br>}<br></code></pre></p><p><strong>Complexity</strong><br>Time: <code>O(nW)</code> pseudo-polynomial. Space: <code>O(W)</code> (1D DP).</p><p><strong>Practical notes</strong></p><p><li>Use meet-in-the-middle, branch-and-bound, or approximate schemes for large <code>W</code> or <code>n</code>.</li></p><p>---</p><p><h1>15) Longest Common Subsequence (LCS)</h1></p><p><strong>Overview</strong><br>Find the longest subsequence present in two sequences. Classic dynamic programming problem with <code>O(nm)</code> DP solution.</p><p><strong>Origin</strong><br>A fundamental string problem in computer science; quadratic DP solution is taught in classic algorithm texts.</p><p><strong>Mathematical representation</strong><br>DP recurrence:</p><p><pre><code><br>LCS[i][j] = 0 if i==0 or j==0<br>else if a[i-1]==b[j-1] LCS[i][j] = 1 + LCS[i-1][j-1]<br>else LCS[i][j] = max(LCS[i-1][j], LCS[i][j-1])<br></code></pre></p><p><strong>Implementation</strong></p><p><pre><code>ts<br>export function lcs(a: string, b: string): number {<br>  const n = a.length, m = b.length;<br>  const dp = Array.from({ length: n + 1 }, () => new Array(m + 1).fill(0));<br>  for (let i = 1; i <= n; i++) for (let j = 1; j <= m; j++) {<br>    if (a[i-1] === b[j-1]) dp[i][j] = dp[i-1][j-1] + 1; else dp[i][j] = Math.max(dp[i-1][j], dp[i][j-1]);<br>  }<br>  return dp[n][m];<br>}<br></code></pre></p><p><strong>Practical notes</strong></p><p><li>LCS is quadratic and hard to beat in general; there are recent subquadratic approximations for special cases.</li></p><p>---</p><p><h1>16) Greatest Common Divisor (GCD) — Euclidean algorithm</h1></p><p><strong>Overview</strong><br>Compute the greatest common divisor <code>gcd(a, b)</code> via repeated remainder operations. Extremely efficient and ancient.</p><p><strong>Origin</strong><br>Described by Euclid in <em>Elements</em>, circa 300 BCE.</p><p><strong>Mathematical representation</strong><br>Euclidean recurrence:</p><p><pre><code><br>gcd(a, b) = gcd(b, a mod b) with gcd(a, 0) = a<br></code></pre></p><p><strong>Implementation</strong></p><p><pre><code>ts<br>export function gcd(a: number, b: number): number {<br>  a = Math.abs(a); b = Math.abs(b);<br>  while (b !== 0) { const t = a % b; a = b; b = t; }<br>  return a;<br>}<br></code></pre></p><p><strong>Practical notes</strong></p><p><li>Extended Euclidean algorithm returns Bézout coefficients useful for modular inverses in cryptography.</li></p><p>---</p><p><h1>Appendix: Benchmark harness & integration notes</h1></p><p><li>The suite includes a single-file harness (TS) that instantiates representative inputs and times runs using <code>performance.now()</code>.</li><br><li>For production benchmarking, add warmup rounds, CPU pinning, and repeated-run logging (CSV), and use system-level profilers if wall-clock precision matters.</li><br><li>Replace placeholder <code>Map</code>-based priority queues with an indexed heap for A\*/Dijkstra to achieve expected asymptotics.</li></p><p>---</p><p><h1>Final remarks</h1></p><p>This deliverable is an actionable technical artifact. If you want I will:</p><p><li>Output the entire TypeScript file for immediate execution with a comprehensive benchmark harness (the code shown in previous interaction is available and can be attached as a file).</li><br><li>Replace recursive FFT with an iterative in-place FFT and provide microbenchmarks comparing both.</li><br><li>Produce unit tests and a CI pipeline (Deno test + coverage) and a CSV export of benchmarks for ingestion.</li></ul></p><p>Tell me which follow-up you want and I will produce the next artifact as an additional deliverable.<br>
        </div>
        
        <div class="footer">
            <p>Algorithm Study Repository - Comprehensive Algorithm Learning Resource</p>
        </div>
    </div>
</body>
</html>